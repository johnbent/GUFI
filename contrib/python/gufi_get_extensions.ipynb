{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6832f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from ast import literal_eval\n",
    "from io import StringIO\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# to do\n",
    "# 1. add -d ' ' to gufi_query so it uses space as delimiter\n",
    "# 2. don't convert ranges to human-friendly until plot time; then remove the stupid code we added to revert them back\n",
    "# 3. instead of just showing some mean values as a function of depth, try to show distributions at each depth\n",
    "#    this might be something like one graph per file-system with a different line per depth or something like that\n",
    "# 4. make the cumulative graphs for the depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb17d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexroots = [\"/mnt/nvme3n1/jbent/scr4/\", \n",
    "              \"/mnt/nvme3n1/jbent/yellprojs/\", \n",
    "              \"/mnt/nvme3n1/jbent/ttscratch/\", \n",
    "              \"/mnt/nvme3n1/jbent/yellusers\", \n",
    "              \"/mnt/nvme3n1/jbent/anony\"]\n",
    "testir = indexroots[0]  \n",
    "#testir = '/mnt/nvme3n1/jbent/jbent_home/'\n",
    "nthreads = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f94b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gufi_command(command,Verbose):    \n",
    "    if Verbose:\n",
    "        print(' '.join(command))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    completed_process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    if completed_process.returncode != 0:\n",
    "        print(f\"An error occurred:\\n{completed_process.stderr.decode('utf-8')}\")\n",
    "        return None\n",
    "    else:\n",
    "        output = completed_process.stdout.decode('utf-8')\n",
    "        output = output.replace('\\u001A', ' ') # some weird character in the output for some reason\n",
    "\n",
    "        if Verbose:\n",
    "            #print(f\"Output:\\n{output}\")\n",
    "            print(f\"Elapsed time: {(end_time - start_time)/60:.2f} minutes\")\n",
    "        return output\n",
    "\n",
    "def run_gufi_select(select, indexroot, nthreads, Verbose=False):\n",
    "    cmd = 'gufi_query'\n",
    "    command = [\n",
    "        cmd,\n",
    "        '-E', select,\n",
    "        '-d', ' ',\n",
    "        '-n', str(nthreads),\n",
    "        indexroot\n",
    "    ]\n",
    "    return run_gufi_command(command,Verbose)\n",
    "\n",
    "def run_gufi_aggregate(indexroot, nthreads, create_int, insert_int, create_agg, insert_agg, select_agg, Verbose=False):\n",
    "    cmd = 'gufi_query'\n",
    "    command = [\n",
    "        cmd,\n",
    "        \"-I\", create_int,\n",
    "        \"-S\", insert_int,\n",
    "        \"-K\", create_agg,\n",
    "        \"-J\", insert_agg,\n",
    "        \"-G\", select_agg,\n",
    "        \"-n\", str(nthreads),\n",
    "        '-d', ' ',\n",
    "        indexroot\n",
    "    ]\n",
    "    return run_gufi_command(command,Verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95964c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gufi_query -E \n",
      "        SELECT pinode, \n",
      "               CASE \n",
      "                    WHEN name NOT LIKE '%.%' THEN 'Null' \n",
      "                    ELSE REPLACE(name, RTRIM(name, REPLACE(name, '.', '')), '') \n",
      "                END AS extension, \n",
      "                COUNT(*) AS count \n",
      "                FROM vrpentries \n",
      "                GROUP BY pinode,extension\n",
      "                ORDER BY count DESC LIMIT 4;\n",
      "         -d   -n 224 /mnt/nvme3n1/jbent/jbent_home/\n",
      "Elapsed time: 0.00 minutes\n",
      "450835 Null 4 450835 json 1 450835 rst 1 450835 txt 1 442845 pyc 3 450898 pyi 2 450900 pyi 3 475171 js 1 467335 css 1 467335 js 1\n"
     ]
    }
   ],
   "source": [
    "# returns a dataframe\n",
    "def get_popular_extensions_by_pinode(Verbose):\n",
    "    select = \"\"\"\n",
    "        SELECT pinode, \n",
    "               CASE \n",
    "                    WHEN name NOT LIKE '%.%' THEN 'Null' \n",
    "                    ELSE REPLACE(name, RTRIM(name, REPLACE(name, '.', '')), '') \n",
    "                END AS extension, \n",
    "                COUNT(*) AS count \n",
    "                FROM vrpentries \n",
    "                GROUP BY pinode,extension\n",
    "                ORDER BY count DESC LIMIT 4;\n",
    "        \"\"\"\n",
    "    output = run_gufi_select(select,testir,nthreads,Verbose)\n",
    "    \n",
    "    if Verbose: \n",
    "        # print 10 lines just for debugging\n",
    "        print(*[f\"{line}\" for line in output.strip().split('\\n')][:10])\n",
    "\n",
    "    # Read the data into a DataFrame\n",
    "    df = pd.read_csv(StringIO(output), sep=' ', header=None, names=['pinode', 'ext', 'count'])\n",
    "\n",
    "    # Initialize columns for strings and integers\n",
    "    for i in range(1, 5):\n",
    "        df[f'ext_mode_{i}']  = None\n",
    "        df[f'ext_count_{i}'] = pd.Series(dtype='Int64')\n",
    "\n",
    "    # Assign values to the new columns\n",
    "    for _, group in df.groupby('pinode'):\n",
    "        indices = group.index\n",
    "        for i, idx in enumerate(indices):\n",
    "            df.at[idx, f'ext_mode_{i+1}']  = group.at[idx, 'ext']\n",
    "            df.at[idx, f'ext_count_{i+1}'] = group.at[idx, 'count']\n",
    "\n",
    "    # Drop the original 'string' and 'integer' columns\n",
    "    df = df.drop(columns=['ext', 'count'])\n",
    "\n",
    "    # Aggregate by 'pinode' and take the first non-null value in each column\n",
    "    result_df = df.groupby('pinode').first().reset_index()\n",
    "    result_df = result_df.set_index('pinode')\n",
    "\n",
    "    return result_df # grouped\n",
    "\n",
    "pin_ext_df = get_popular_extensions_by_pinode(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e56bdf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ext_mode_1</th>\n",
       "      <th>ext_count_1</th>\n",
       "      <th>ext_mode_2</th>\n",
       "      <th>ext_count_2</th>\n",
       "      <th>ext_mode_3</th>\n",
       "      <th>ext_count_3</th>\n",
       "      <th>ext_mode_4</th>\n",
       "      <th>ext_count_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396893</th>\n",
       "      <td>bash_history</td>\n",
       "      <td>1</td>\n",
       "      <td>bash_logout</td>\n",
       "      <td>1</td>\n",
       "      <td>bash_profile</td>\n",
       "      <td>1</td>\n",
       "      <td>bashrc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401763</th>\n",
       "      <td>Null</td>\n",
       "      <td>3</td>\n",
       "      <td>pub</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401764</th>\n",
       "      <td>txt</td>\n",
       "      <td>2</td>\n",
       "      <td>gitignore</td>\n",
       "      <td>1</td>\n",
       "      <td>md</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401765</th>\n",
       "      <td>Null</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401766</th>\n",
       "      <td>Null</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491644</th>\n",
       "      <td>Null</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491645</th>\n",
       "      <td>Null</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491646</th>\n",
       "      <td>Null</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491647</th>\n",
       "      <td>Null</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491648</th>\n",
       "      <td>Null</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2764 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ext_mode_1  ext_count_1   ext_mode_2  ext_count_2    ext_mode_3  ext_count_3 ext_mode_4  ext_count_4\n",
       "pinode                                                                                                        \n",
       "396893  bash_history            1  bash_logout            1  bash_profile            1     bashrc            1\n",
       "401763          Null            3          pub            1          None         <NA>       None         <NA>\n",
       "401764           txt            2    gitignore            1            md            1       None         <NA>\n",
       "401765          Null            8         None         <NA>          None         <NA>       None         <NA>\n",
       "401766          Null            1         None         <NA>          None         <NA>       None         <NA>\n",
       "...              ...          ...          ...          ...           ...          ...        ...          ...\n",
       "491644          Null            5         None         <NA>          None         <NA>       None         <NA>\n",
       "491645          Null            5         None         <NA>          None         <NA>       None         <NA>\n",
       "491646          Null            5         None         <NA>          None         <NA>       None         <NA>\n",
       "491647          Null            5         None         <NA>          None         <NA>       None         <NA>\n",
       "491648          Null            5         None         <NA>          None         <NA>       None         <NA>\n",
       "\n",
       "[2764 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make it so we can see more\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pin_ext_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4daf00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "For some reason, wordcloud doesn't work on hpe1. Just pickle it and make the wordcount elsewhere. Ugh.\n"
     ]
    }
   ],
   "source": [
    "# just for fun, turn it into a word map\n",
    "# first get a global count of each extension\n",
    "\n",
    "def df_to_global_count(df,num_cols):\n",
    "    # Assuming df is your DataFrame\n",
    "\n",
    "    # Initialize a dictionary to store the sums\n",
    "    sums = {}\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Iterate over each string-int pair\n",
    "        for i in range(1, num_cols+1):\n",
    "            str_col = f'ext_mode_{i}'\n",
    "            int_col = f'ext_count_{i}'\n",
    "            if pd.notna(row[str_col]) and pd.notna(row[int_col]):\n",
    "                # Add to the sum in the dictionary\n",
    "                sums[row[str_col]] = sums.get(row[str_col], 0) + row[int_col]\n",
    "\n",
    "    return sums\n",
    "\n",
    "sums = df_to_global_count(pin_ext_df,4)\n",
    "print(len(sums))\n",
    "with open('/tmp/ext_counts.pkl', 'wb') as file:\n",
    "    pickle.dump(sums, file)\n",
    "\n",
    "def to_wordcloud(word_counts):\n",
    "    # Specify the path to the DejaVu Sans Regular font\n",
    "    font_path = '/usr/share/fonts/dejavu/DejaVuSans.ttf'\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate_from_frequencies(word_counts)\n",
    "\n",
    "    # Display the word cloud using matplotlib\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "#to_wordcloud(sums)\n",
    "print(\"For some reason, wordcloud doesn't work on hpe1. Just pickle it and make the wordcount elsewhere. Ugh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde8d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the name and inode for each directory\n",
    "def get_pinode_name_map(Verbose):\n",
    "    itab='intermediate' # intermediate table\n",
    "    atab='aggregate' # aggregate table\n",
    "    stab='vrsummary' # source table\n",
    "    cstr='(inode INT64, name TEXT)' # create string\n",
    "    sstr='inode,name' # select string\n",
    "    output = run_gufi_aggregate(\n",
    "            indexroot  = testir, \n",
    "            nthreads   = f\"{nthreads}\",\n",
    "            create_int = f\"CREATE TABLE {itab} {cstr}\",\n",
    "            insert_int = f\"INSERT INTO {itab} SELECT {sstr} FROM {stab}\",\n",
    "            create_agg = f\"CREATE TABLE {atab} {cstr}\",\n",
    "            insert_agg = f\"INSERT INTO {atab} SELECT {sstr} FROM {itab}\",\n",
    "            select_agg = f\"SELECT {sstr} FROM {atab}\",\n",
    "            Verbose    = Verbose\n",
    "    )\n",
    "    # output is like \"37 foo\\n45 bar\\nETC\"; convert into dict and return that\n",
    "    result_dict = {line.split()[0]: line.split()[1] for line in output.strip().split('\\n')}\n",
    "    return result_dict\n",
    "\n",
    "# pin_name_map = get_pinode_name_map(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f8a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some sanity checking to see if the pinodes are the same between the two maps\n",
    "# this doesn't work because we used to get ext counts into a dict and now we get into a dataframe\n",
    "# so woould have to modify this to make it work again\n",
    "check_sanity = False\n",
    "if check_sanity:\n",
    "    sanity = set(pin_ext_map.keys()) - set(pin_name_map.keys())\n",
    "    if len(sanity) != 0:\n",
    "        print(\"Some files have nonexistant parents\")\n",
    "        print(sanity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
